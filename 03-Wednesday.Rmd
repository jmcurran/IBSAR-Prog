# Programme And Abstracts For Wednesday 29^th^ Of November {-}
<p style="color:white;background-color:red;text-align:center">Keynote: Wednesday 29<sup>th</sup> 9:00 Mantra</p>
## Statistics On Street Corners {-}
<p style="text-align:center">
Dianne Cook<br />
Monash University<br />
</p>
Perceptual research is often conducted on the street, with convenience sampling of pedestrians who happen to be passing by. It is through experiments conducted using passer-bys that we have learned about the effect of change-blindness (https://www.youtube.com/watch?v=FWSxSQsspiQ) is in play outside the laboratory. 

In data science, plots of data become important tools for observing patterns, making decisions, and communicating findings. But plots of data can be viewed differently by different observers, and often provoke skepticism about whether what you see "is really there?" With the availability of technology that harnesses statistical randomisation techniques and input from crowds we can provide objective evaluation of structure read from plots of data. 

This talk describes an inferential framework for data visualisation, and the protocols that can be used to provide estimates of p-values, and power. I will discuss the experiments that we have conducted that (1) show that the crowd-sourcing does provide results similar to statistical hypothesis testing, (2) how this can be used to improve plot design, (3) p-values in situations where no classical tests exist. Examples from ecology and agriculture will be shown. 

Joint work with Heike Hofmann, Andreas Buja, Deborah Swayne, Hadley Wickham, Eun-kyung Lee, Mahbubul Majumder, Niladri Roy Chowdhury, Lendie Follett, Susan Vanderplas, Adam Loy, Yifan Zhao, Nathaniel Tomasetti
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:30 Narrabeen</p>
## Estimating Overdispersion In Sparse Multinomial Data {-}
<p style="text-align:center">
Farzana Afroz<br />
University of Otago<br />
</p>
The phenomenon of overdispersion arises when the data are more variable than we expect from the fitted model. This issue often arises when fitting a Poisson or a binomial model. When overdispersion is present, ignoring it may lead to misleading conclusions, with standard errors being underestimated and overly-complex models being selected. In our research we considered overdispersed multinomial data, which can arise in many research areas. Two approaches can be used to analyse overdispersed multinomial data; the use of the quasilikelihood method or explicit modelling of the overdispersion using, for example, a Dirichlet-multinomial or finite-mixture distribution. Use of quasilikelihood has the advantage of only requiring specification of the first two moments of the response variable. For sparse data, such as in a contingency table with many low expected counts, use of quasilikelihood to estimate the amount of overdispersion will be particularly useful, as it may be difficult to obtain reliable estimates of the parameters in a Dirichlet-multinomial or finite-mixture model. I consider four estimators of the amount of overdispersion in sparse multinomial data, discuss their theoretical properties and provide simulation results showing their performance in terms of bias, variance and mean squared error.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:30 Gunnamatta</p>
## Assessing Mud Crab Meat Fullness Using Non-Invasive Technologies {-}
<p style="text-align:center">
Carole Wright, Steve Grauf, Brett Wedding, Paul Exley, John Mayze, and Sue Poole<br />
Queensland Department of Agriculture and Fisheries<br />
</p>
The decision of whether a mud crab should be retained at harvest has traditionally been based on shell hardness. This is most commonly assessed by using thumb pressure applied to the carapace of the mud crab. The carapace of a recently moulted mud crab will flex considerably and is therefore returned to the water. This assessment has also been used to divide mud crabs into three meat fullness grades (A, B and C). The higher meat fullness grade A mud crabs fetch a greater price at market compared to the lower B and C grades. The subjective nature of this assessment will always result in disputes at the boundaries of the grades. By developing a more objective science-based method downgrades at the market will be reduced while consumer satisfaction and the overall industry profitability will increase.

A scoping study was conducted that evaluated innovative non-invasive technologies to assess mud crab meat fullness based on percentage yield recovery of cooked meat from the dominant individual mud crab claws. The non-invasive technologies assessed included near infrared spectroscopy (NIRS), candling using visible light, and acoustic velocity. NIRS showed the most potential and was reassessed in a second study with slight improvements to spectra capture methods and NIR light sources.

94 live mud crabs from the Moreton Bay area were used in the second study. Partial least squares regression (PLS-R) was performed to build a calibration model to predict the percentage yield recovery of cooked meat based on the spectral data. The PLS-R had $R^2=0.77$ and $RMSECV=4.8$.

A principal components linear discriminant analysis (PC-LDA) was also conducted to discriminate between the standard three grades of mud crab meat fullness. This was compared to the industry standard shell hardness method. The NIRS PC-LDA achieved a minimum of 76% correct classification for each of the three grades, compared to 24% for the shell hardness method.

The non-invasive technologies trialled along with the results will be discussed in this talk.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:30 Bundeena</p>
## Analysis Of Multivariate Binary Longitudinal Data: Metabolic Syndrome During Menopausal Transition {-}
<p style="text-align:center">
Geoff Jones<br />
Massey University<br />
</p>
Metabolic syndrome (MetS) is a major multifactorial condition that predisposes adults to type 2 diabetes and CVD. It is defined as having at least three of five cardiometabolic risk components: 1) high fasting triglyceride level, 2) low high-density lipoprotein cholesterol, 3) elevated fasting plasma glucose, 4) large waist circumference (abdominal obesity), and 5) hypertension. In the US Study of Women’s Health Across the Nation (SWAN), a 15-year multi-centre prospective cohort study of women from five racial/ethnic groups, the incidence of MetS increased as midlife women underwent the menopausal transition (MT). A model is sought to examine the interdependent progression of the five MetS components and the influence of demographic covariates.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:50 Narrabeen</p>
## Statistical Analysis Of Coastal And Oceanographic Influences On The Queensland Scallop Fishery {-}
<p style="text-align:center">
Wen-Hsi Yang<sup>1</sup>, Anthony J. Courtney<sup>2</sup>, Michael F. O’neill<sup>2</sup>, Matthew J. Campbell<sup>2</sup>, George M. Leigh<sup>2</sup>, and Jerzy A. Filar<sup>1</sup><br />
<sup>1</sup>Universtiy of Queensland<br />
<sup>2</sup>Queensland Department of Agriculture and Fisheries<br />
</p>
The saucer scallop (Ylistrum balloti) otter-trawl fishery used to be the most valuable commercially-fished species in Queensland ocean waters. Over the last few years, there has been growing concern among fishers, fishery managers and scientists over the decline in catch rates and annual harvest. A quantitative assessment conducted in 2016 showed that scallop abundance was at an historic low level. The assessment used data sourced from the fishery and independent surveys. Further information on coastal and oceanographic influences are available and may reveal new factors that influence population abundance of scallops and improve management of the fishery. In this study, scallop catch rate abundance data and coastal and physical oceanographic variables (e.g. sea surface temperature anomalies, coastal freshwater flow and Chlorophyll-a) were modelled to identify spatial and temporal environmental processes important for consideration in fishery management procedures.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:50 Gunnamatta</p>
## Saved By The Experimental Design: Testing Bycatch Reduction And Turtle Exclusion Devices In The Png Prawn Trawl Fishery {-}
<p style="text-align:center">
Emma Lawrence and Bill Venables<br />
CSIRO<br />
</p>
In trawling for prawns, the prawn catch is often only a small part of the results of any one trawl, with the remainder called "bycatch". Reducing the bycatch component, while maintaining the prawn catch, is an important industry goal, primarily for environmental accreditation purposes, but also for economic reasons.

 We designed an at-sea trial for the Gulf of Papua Prawn Fishery, involving four vessels each towing "quad gear" (that is, 4 separate, but linked trawl nets) in each trawl shot, over 18 days. The experiment was designed to assess the effectiveness of 27 combinations of Turtle Excluder Devices (TEDs) and Bycatch Reduction Devices, (BRDs), with a control net, without any attached device as one of the nets in each quad. At Biometrics 2015 we discussed how we used simulated annealing to generate a highly efficient design, in several stages, to meet the large number of highly specific logistical constraints. 

 The focus of this talk will be the analysis, which also proved somewhat challenging. We will present the results of our analysis and demonstrate why putting the time into thinking about and generating a non-standard experimental design allowed us to accommodate the various glitches and misfortunes that always seem to happen at sea.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 10:50 Bundeena</p>
## Comparison Of Separable And Non-Separable Models In Analysis Of Macadamia Four-Way Multi-Harvest Multi-Environment Variety Selection Data {-}
<p style="text-align:center">
Joanne De Faveri and Dougal Russell<br />
Queensland Department of Agriculture and Fisheries<br />
</p>
Variety selection in Horticulture crops usually involves testing varieties in field trials at multiple locations over a number of years with repeated measurements on each tree or plant. The aim of these trials is to get accurate predictions for variety performance over times and environments and to investigate variety by environment (location and time) interaction. In the analysis of such data there are a number of issues to account for including the spatial and temporal correlation between repeated measurements on plants in the field. There is also the need to adequately model the genetic covariance structure between varieties across sites and harvest times. In this talk we will look at the linear mixed model analysis of yield data from macadamia varieties grown on two rootstocks at multiple sites, measured over multiple years. This four-way multi-harvest, multi-environment variety by rootstock data may be modelled using separable or non-separable models at both the genetic and residual levels. While separable models are desirable for their ease of interpretation and computing advantages, the structure they assume is quite restrictive and may not hold in practice. Alternatives may include the 2DIMVAR1 (De Faveri et al 2017) residual models and four-way genetic models using factor analytic models (Smith et al 2001). We investigate and compare the different approaches.

References:J De Faveri, A.P Verbyla, B. Cullis, W.Pitchford and R.Thompson (2017) Residual variance-covariance modelling in analysis of multivariate data from variety selection trials. Journal of Agricultural, Biological & Environmental Statistics 22, 1-22 Smith A, Cullis B and Thompson R (2001) Analysing variety by environment data using multiplicative mixed models and adjustments for spatial field trend. Biometrics 57, 1138-1147
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:10 Narrabeen</p>
## Subtractive Stability Measures For Improved Variable Selection {-}
<p style="text-align:center">
Connor Smith<sup>1</sup>, Samuel Müller<sup>1</sup>, and Boris Guennewig<sup>1</sup><br />
<sup>1</sup>University of Sydney<br />
<sup>2</sup>University of New South Wales<br />
</p>
This talk builds upon the Invisible Fence (Jiang et al., 2011) a promising model selection method. Utilizing a combination of coeffcient, scale and deviance estimates we are able to improve this resampling based model selection method for regression models, both linear and general linear models. The introduction of a variable inclusion plot allows for a visual representation for the stability of the model selection method as well as the variables bootstrapped rank. The suggested methods will be applied to both simulated and real examples with comparisons about both computational time and effectiveness made to selections through alternative selection procedures. We will report on our latest results from ongoing work in scaling up subtractive stability measures when the numbers of features is large.

References: Jiang, J., Nguyen, T., & Rao, J. S. (2011). Invisible fence methods and the identification of differentially expressed gene sets. Statistics and Its Interface, 4(3), 403-415.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:10 Bundeena</p>
## A Comparison Of Multiple Imputation Methods For Missing Data In Longitudinal Studies {-}
<p style="text-align:center">
Md Hamidul Huque<sup>1</sup>, Katherine Lee<sup>1</sup>, Julie Simpson<sup>2</sup>, and John Carlin<sup>1</sup><br />
<sup>1</sup>Murdoch Childrens Research Institute<br />
<sup>2</sup>University of Melbourne<br />
</p>
Multiple imputation (MI) for imputing missing data are increasingly used in longitudinal studies where data are missing due to non-response and lost to follow-up. Standard multivariate normal imputation (MVNI) and fully conditional specifications (FCS) are the principle imputation framework available for imputing cross-sectional missing data. A number of methods has been suggested in the literature to impute longitudinal data including (i) use of standard FCS and MVNI with repeated measurements as separate distinct variables (ii) use of imputation methods based on generalized linear mixed models. No clear evaluation of the relative performance of available MI methods in the context of longitudinal data. We present a comprehensive comparison of the all the available methods for imputation longitudinal data in the context of estimating coefficient for both linear regression model and linear mixed effect model. We also compared the performance of the methods to impute both binary and continuous data. A total of 10 different methods (MVNI, JM-pan, JM-jomo, standard FCS, FCS-twofold, FCS-MTW, FCS-2lnorm, FCS-2lglm, FCS-2ljomo and FCS-Blimp) are compared in terms of bias, standard error and coverage probability of the estimated regression coefficients. These methods are compared using a simulation study based on a previously conducted analysis exploring the association between the burden of overweight and quality of life (QoL) using data from the Longitudinal Study of Australian Children (LSAC). We found that both standard FCS and MVNI provide reliable estimates and coverage of the regression parameters. Among other methods linear mixed models based methods, JM-jomo and FCS-Blimp approaches hold great promise.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:30 Narrabeen</p>
## Species Distribution Modelling For Combined Data Sources {-}
<p style="text-align:center">
Ian Renner<sup>1</sup> and Olivier Gimenez<sup>2</sup><br />
<sup>1</sup>University of Newcastle<br />
<sup>2</sup>Centre d’Ecologie Fonctionnelle et Evolutive<br />
</p>
Increasingly, multiple sources of species occurrence data are available for a particular species, collected through different protocols. For single-source models, a variety of methods have been developed: point process models for presence-only data, logistic regression for presence-absence data obtained through single-visit systematic surveys, and occupancy modelling for detection/non-detection data obtained through repeat-visit surveys. In situations for which multiple sources of data are available to model a species, these sources may be combined via a joint likelihood expression. Nonetheless, there are questions about how to interpret the output from such a combined model and how to diagnose potential violations of model assumptions such as the assumption of spatial independence among points.

 In this presentation, I will explore questions of interpretation of the output from these combined approaches, as well as propose extensions to current practice through the introduction of a LASSO penalty, source weights to account for differing quality of data, and models which account for spatial dependence among points. This approach will be demonstrated by modelling the distribution of the Eurasian lynx in eastern France.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:30 Gunnamatta</p>
## A Factor Analytic Mixed Model Approach For The Analysis Of Genotype By Treatment By Environment Data {-}
<p style="text-align:center">
Alison Smith, Brian Cullis, and Lauren Borg<br />
University of Wollongong<br />
</p>
The accurate evaluation of genotype performance for a range of traits, including disease resistance, is of great importance to the productivity and sustainability of major Australian commercial crops. Typically, the data generated from crop evaluation programmes arise from a series of field trials known as multi-environment trials (METs), which investigate genotype performance over a range of environments.

In evaluation trials for disease resistance, it is not uncommon for some genotypes to be chemically treated against the afflicting disease. An important example in Australia is the assessment of genotypes for resistance to blackleg disease in canola crops where it is common practice to treat canola seeds with a fungicide. Genotypes are either grown in trials as treated, untreated or as both.

There are a number of methods for the analysis of MET data. These methods, however, do not specifically address the analysis of data with an underlying three-way structure of genotype by treatment by environment (GxTxE). Here, we propose an extension of the factor analytic mixed model approach for MET data, using the canola blackleg data as the motivating example.

Historically in the analysis of blackleg data, the factorial genotype by treatment structure of the data was not accounted for. Entries, which are the combinations of genotypes and fungicide treatments present in trials, were regarded as `genotypes’ and a two-way analysis of ‘genotypes’ by environments was conducted.

The analysis of our example showed that the accuracy of genotype predictions, and thence information for growers, was substantially improved with the use of the three-way GxTxE approach compared with the historical approach.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:30 Bundeena</p>
## The Impact Of Cohort Substance Use Upon Likelihood Of Transitioning Through Stages Of Alcohol And Cannabis Use And Use Disorder: Findings From The Australian National Survey On Mental Health And Well-Being {-}
<p style="text-align:center">
Louisa Degenhardt<sup>1</sup>, Meyer Glantz<sup>2</sup>, Chrianna Bharat<sup>1</sup>, Amy Peacock<sup>1</sup>, Luise Lago<sup>1</sup>, Nancy Sampson<sup>3</sup>, and Ronald Kessler<sup>3</sup><br />
<sup>1</sup>National Drug and Alcohol Research Centre<br />
<sup>2</sup>National Institute on Drug Abuse<br />
<sup>3</sup>Harvard University<br />
</p>
The aims of the present study were to use population-level Australian data to estimate prevalence and speed of transitions across stages of alcohol and cannabis use, abuse and dependence, and remission from disorder, and consider the potential impacts that an individual’s age and sex cohort’s level of substance use predicted transitions into and out of substance use. 
Data on lifetime history of use, DSM-IV use disorders, and remission from these disorders were collected from participants (n=8,463) in the 2007 Australian National Survey of Mental Health and Wellbeing using the Composite International Diagnostic Interview. 

Lifetime prevalence of alcohol use, regular use, abuse, dependence, and remission from abuse and dependence were 94.1%, 64.5%, 22.1%, 4.0%, 16.1% and 2.1%, respectively. Unconditional lifetime prevalence of cannabis use, abuse, dependence, and remission from abuse and dependence were 19.8%, 6.1%, 1.9%, 4.0% and 1.5%. Increases in the estimated proportion of people in the respondent’s sex and age cohort who used alcohol/cannabis as of a given age were significantly associated with most transitions from use through to remission beginning at the same age.
Clear associations were documented between cohort-level prevalence of substance use and personal risk of subsequent transitions of individuals in the cohort from use to greater substance involvement. This relationship remained significant over and above associations involving the individual’s age of initiation. These findings have important implications for our understanding of the causal pathways into and out of problematic substance use.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:50 Narrabeen</p>
## The LASSO On Latent Indices For Ordinal Predictors In Regression {-}
<p style="text-align:center">
Francis Hui<sup>1</sup>, Samuel Mueller<sup>2</sup>, and Alan Welsh<sup>1</sup><br />
<sup>1</sup>ANU<br />
<sup>2</sup>University of Sydney<br />
</p>
Many applications of regression models involve ordinal categorical predictors. A motivating example we consider is ordinal ratings from individuals responding to questionnaires regarding their workplace in the Household Income and Labour Dynamics in Australia (HILDA) survey, with the aim being to study how workplace conditions (main and possible interaction effects) affect their overall mental wellbeing. A common approach to handling ordinal predictors is to treat each predictor as a factor variable. This can lead to a very high-dimensional problem, and has spurred much research into penalized likelihood methods for handling categorical predictors while respecting the marginality principle. On the other hand, given the ordinal ratings are often regarded as manifestations of some latent indices concerning different aspects of job quality, then a more sensible approach would be to first perform some sort of dimension reduction before entering the predicted indices into a regression model. In applied research this is often performed as a two-stage procedure, and in doing so fails to utilize the response in order to better predict the latent indices themselves.

In this talk, we propose the LASSO on Latent Indices (LoLI) for handling ordinal categorical predictors in regression. The LoLI model simultaneously constructs a continuous latent index for each or groups of ordinal predictors and models the response as a function of these (and other predictors if appropriate) including potential interactions, with a composite LASSO type penalty added to perform selection on main and interaction effects between the latent indices. As a single-stage approach, the LoLI model is able to borrow strength from the response to improve construction of the continuous latent indices, which in turn produces better estimation of the corresponding regression coefficients. Furthermore, because of the construction of latent indices, the dimensionality of the problem is substantially reduced before any variable selection is performed. For estimation, we propose first estimating the cutoffs relating the observed ordinal predictors to the latent indices. Then conditional on these cutoffs, we apply a penalized Expectation Maximization algorithm via importance sampling to estimate the regression coefficients. A simulation study demonstrates the improved power of the LoLI model at detecting truly important ordinal predictors compared to both two-stage approaches and using factor variables, and better predictive and estimation performance compared to the commonly used two-stage approach.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 11:50 Gunnamatta</p>
## Whole‑Genome QTL Analysis For Nested Association Mapping Populations {-}
<p style="text-align:center">
Maria Valeria Paccapelo<sup>1</sup>, Alison Kelly<sup>1</sup>, Jack Christopher<sup>2</sup>, and Arunas Verbyla<sup>3</sup><br />
<sup>1</sup>Queensland Department of Agriculture and Fisheries<br />
<sup>2</sup>Queensland Alliance for Agriculture and Food<br />
<sup>3</sup>Data61<br />
<sup>4</sup>CSIRO<br />
</p>
Genetic dissection of quantitative traits in plants has become an important tool in breeding of improved varieties. The most commonly used methods to map QTL are linkage analysis in bi-parental populations and association mapping in diversity panels. However, bi-parental populations are restricted in terms of allelic diversity and recombination events. Despite the fact that association mapping overcomes these limitations, it has low power to detect rare alleles associated with a trait of interest. Multi-parent populations such as multi-parent advanced generation inter-cross (MAGIC) and nested association mapping (NAM) populations have been developed to combine strengths of both mapping approaches, capturing more recombination events and allelic diversity than bi-parental populations and in a greater frequency than a diversity panel. Nested association mapping uses multiple RIL families connected by a single common parent. Such a population structure presents some additional challenges compared to traditional mapping, in particular the population design and the large number of molecular markers that need to be integrated simultaneously into the analysis. We present a method for QTL mapping for NAM populations adapted from multi-parent whole genome average interval mapping (MPWGAIM) where the NAM design is incorporated through the probability of inheriting founder alleles for every marker across the genome. This method is based on a mixed linear model in a one-stage analysis of raw phenotypes together with markers. It simultaneously scans the whole-genome through an iterative process leading to a multi-locus model. The approach was applied to a wheat NAM population in order to perform QTL mapping for plant height. The method was developed in R, with main dependencies being the R packages MPWGAIM and asreml. This approach establishes the basis for further studies and extensions such as the combination of multiple NAM populations.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 12:10 Narrabeen</p>
## Fast And Approximate Exhaustive Variable Selection For GLMs With APES {-}
<p style="text-align:center">
Samuel Mueller, Garth Tarr, Jean Yang, and Kevin Wang<br />
University of Sydney<br />
</p>
Obtaining maximum likelihood estimates for generalised linear models (GLMs) is computationally intensive and remains as the major obstacle for performing all subsets variable selection. Exhaustive exploration of the model space, even for a moderately large number of covariates, remains a formidable challenge for modern computing capabilities. On the other hand, efficient algorithms for exhaustive searches do exist for linear models, most notably the leaps and bound algorithm and, more recently, the mixed integer optimisation algorithm. In this talk, we present APES (APproximated Exhaustive Search) a new method that approximates all subset selection for a given GLM by reformulating the problem as a linear model. The method works by learning from observational weights in a correct/saturated generalised linear regression model. APES can be used in partnership with any other state-of-the-art linear model selection algorithm, thus enabling (approximate) exhaustive model exploration in dimensions much higher than previously feasible. We will demonstrate that APES model selection is competitive against genuine exhaustive search via simulation studies and applications to health data. Extensions to a robust setting is also possible.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 12:10 Gunnamatta</p>
## Order Selection Of Factor Analytic Models For Genotype X Environment Interaction {-}
<p style="text-align:center">
Francis Hui<sup>1</sup>, Emi Tanaka<sup>2</sup>, and David Warton<sup>3</sup><br />
<sup>1</sup>ANU<br />
<sup>2</sup>University of Sydney<br />
<sup>3</sup>University of New South Wales<br />
</p>
Factor analytic (FA) models are widely used across a range of disciplines owing to computational advantages from dimension reduction and possible ability to interpret the factors. In plant breeding, FA model provides a natural framework to model the genotype x environment interaction. An FA model is dictated by the number of factors (order of the model). A higher order lends to more parameters in the model and this necessitates the order selection to achieve parsimony. We introduce an order selection method via the ordered factor lasso (OFAL). We illustrate its performance based on a simulation on a real wheat yield multi-environmental trial.
<div style="page-break-before:always;"></div>
<p style="color:white;background-color:red;text-align:center">Keynote: Wednesday 29<sup>th</sup> 13:40 Mantra</p>
## Statistical Strategies For The Analysis Of Large And Complex Data {-}
<p style="text-align:center">
Louise Ryan<sup>1</sup>, Stephen Wright<sup>1</sup>, and Hon Hwang<sup>1</sup><br />
<sup>1</sup>University of Technology Sydney<br />
<sup>2</sup>Harvard T. H. Chan School of Public Health<br />
<sup>3</sup>Australian Red Cross<br />
</p>
This talk will focus on challenges that arise when faced with the analysis of datasets that are too large for standard statistical methods to work properly. While one can always go for the expensive solution of getting access to a more powerful computer or cluster, it turns out that there are some simple statistical strategies that can be used. In particular, we'll discuss the use of so called "Divide and Recombine" strategies that relegate some of the work to be done in a distributed fashion, for example via Hadoop. Combining these strategies with clever subsampling and data coarsening ideas can result in datasets that are small enough to manage on a standard desktop machine, with only minimal efficiency loss. The ideas are illustrated with data from the Australian Red Cross.
<div style="page-break-before:always;"></div>
<p style="background-color:#ccccff;text-align:center">Wednesday 29<sup>th</sup> 14:30 Narrabeen</p>
## Optimal Experimental Design For Functional Response Experiments {-}
<p style="text-align:center">
Christopher Drovandi and Jeff Zhang<br />
Queensland University of Technology<br />
</p>
Functional response models are important in understanding predator-prey interactions. The development of functional response methodology has progressed from mechanistic models to more statistically motivated models that can account for variance and the over-dispersion commonly seen in the datasets collected from functional response experiments. However, little information seems to be available to those wishing to prepare optimal parameter estimation designs for functional response experiments. We develop a so-called exchange design optimisation algorithm suitable for integer-valued design spaces, which for the motivating functional response experiment involves selecting the number of prey used for each observation. Further, we develop and compare new utility functions for performing robust opt